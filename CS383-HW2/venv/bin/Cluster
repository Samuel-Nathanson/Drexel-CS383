import numpy as np
import sys
from numpy import genfromtxt
import random as rand
import copy
import math
import time

import plotly.graph_objs as go
import matplotlib.pyplot as plt
import scipy.integrate as integrate
import matplotlib.animation as animation
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.patches as mpatches
# init_notebook_mode()

stopdist = 2e-23

# To solve this problem, you must
# Generate a Video, where each frame is the plot of feature x vs feature y
# Generate a video from multiple 2D arrays
# Color the observations based on the reference vector associated with them

def hsl_to_rgb(h, s, l):
    def hue_to_rgb(p, q, t):
        t += 1 if t < 0 else 0
        t -= 1 if t > 1 else 0
        if t < 1/6: return p + (q - p) * 6 * t
        if t < 1/2: return q
        if t < 2/3: p + (q - p) * (2/3 - t) * 6
        return p

    if s == 0:
        r, g, b = l, l, l
    else:
        q = l * (1 + s) if l < 0.5 else l + s - l * s
        p = 2 * l - q
        r = hue_to_rgb(p, q, h + 1/3)
        g = hue_to_rgb(p, q, h)
        b = hue_to_rgb(p, q, h - 1/3)

    return r, g, b

def updatePlot(data, reference_vectors, associations, it, purities):
    # reference_vectors:
    #       k vectors displayed as dots
    #       color, in order:
    # data: Each observation will have D features and an associated reference vector
    #       Displayed as an X, with color dependent on reference vector
    # i: iteration number
    # {'b', 'g', 'r', 'c', 'm', 'y', 'k', 'w'};

    h = 0
    colorIncr = 1 / len(reference_vectors)

    plt.clf()

    # 2D Plot
    if len(data[0]) == 2:

        # plot data
        for i in range(0, len(data)):
            x = data[i][0]
            y = data[i][1]
            h = associations[i] * colorIncr
            plt.scatter(x, y, c=hsl_to_rgb(h, 1, .5), marker='x')

        # plot reference vector
        h=0
        for reference_vector in reference_vectors:
            x = reference_vector[0]
            y = reference_vector[1]
            plt.scatter(x, y, c=hsl_to_rgb(h, 1, .5), marker='o', s=20**2)
            h += colorIncr

    # 3D Plot
    else:
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')

        #plot data
        for i in range(0, len(data)):
            x = data[i][0]
            y = data[i][1]
            z = data[i][2]
            h = associations[i] * colorIncr
            ax.scatter(x,y,z, c=hsl_to_rgb(h,1,.5), marker='x')

        # plot reference vector
        h=0
        for reference_vector in reference_vectors:
            x = reference_vector[0]
            y = reference_vector[1]
            z = reference_vector[2]
            ax.scatter(x, y, z, c=hsl_to_rgb(h, 1, .5), marker='o', s=20**2)
            h += colorIncr

    # plot reference vectors
        # x's, y's, z's - can transpose and then plot
        # 2d or 3d graph

    # plot data

    # plt.scatter(data[0], data[1], c="g", marker="x")

    # display purities
    # generate Patches
    patches = list()
    strng = ''
    for i in range(0, len(purities)):
        strng += "Purity " + str(i) + ": " + str(purities[i]) + "\n"
        h = i * colorIncr
        patch = mpatches.Patch(label=strng)
        plt.legend(handles=[patch])

    plt.title("Iteration " + str(it))
    plt.show()

def l2(a, b):
    if len(a) != len(b):
        exit(2)

    dis = 0;

    for i in range(0, len(a)):
        val = a[i] - b[i]
        dis+= val*val

    dis = math.sqrt(dis)
    return dis

def clusterChange(prevCluser, newCluster):

    # k observations of length D
    dis = 0
    for k in range(0, len(newCluster)):
        dis += l2(newCluster[k], prevCluser[k])

    return dis

def myKMeans(X, k, labels):


    # Choose initial reference vectors
    rand.seed(0)
    r = [[i] for i in range(len(X))]
    rand.shuffle(r)

    reference_vecs = copy.deepcopy(X[r[0]])
    for i in range(1, k):
        new_reference_vec = copy.deepcopy(X[r[i]])
        reference_vecs = np.vstack([reference_vecs, new_reference_vec])

    # Calculate new reference Vector

    # populate cluster_associations from reference_vecs and X
    # cluster_associations = list()
    iteration = 0
    #emulate a do-while loop
    while True:
        #time.sleep(1)

        cluster_associations = list()
        for observation in X:
            best_reference_vec_index = -1
            best_reference_vec_distance = 99999
            for i in range(0, len(reference_vecs)):
                cluster = reference_vecs[i]
                dis = l2(observation, cluster)
                if dis < best_reference_vec_distance:
                    best_reference_vec_index = i
                    best_reference_vec_distance = dis
            cluster_associations.append(best_reference_vec_index)

        new_reference_vecs = list()
        for i in range(0,len(reference_vecs)):
            sum = np.zeros(len(X[0])) # initialize sum as a matrix of dimension D with all zeroes
            count = 0
            # compute new reference vector as the mean of those associated with it
            for j in range(0,len(cluster_associations)):
                # find the observations associated with reference vec i
                if(cluster_associations[j] == i):
                    count += 1
                    sum = np.add(sum, X[j])
            # calculate new mean, which is really the new reference vector
            new_reference_vec = sum / count
            # append new_reference_vec to new_reference_vecs
            if len(new_reference_vecs) == 0:
                new_reference_vecs = new_reference_vec
            else:
                new_reference_vecs = np.vstack([new_reference_vecs, new_reference_vec])

        # now, new_reference_vecs should be a list of size K

        if iteration != 0 and clusterChange(reference_vecs, new_reference_vecs) < stopdist:
            reference_vecs_data = copy.deepcopy(reference_vecs)
            cluster_associations_data = copy.deepcopy(cluster_associations)


            break
        else:
            reference_vecs = new_reference_vecs
            iteration += 1

        # Compute Purity of k clusters
        # for each reference vector,
        #   find all of its associated observations in X
        #   if X is associated to label -1, negativeCount ++
        #   if X is asosciated to label 1, positiveCount ++
        # if negative count > positive count
        #   purity of this cluster = negative count / cluster size
        # else
        #   purity of this cluster = positive count / cluster size

        purities = list()
        for k in range(0,len(reference_vecs)):

            #for purity calculation
            count = 0
            negative_count = 0;
            positive_count = 0;

            # Compute Purity of this Cluster
            for j in range(0, len(cluster_associations)):
                if cluster_associations[j] != k:
                    continue
                obs = X[j]
                label = labels[j]
                if label == -1:
                    negative_count += 1
                else:
                    positive_count += 1
                count += 1
            # now we have negative count, positive count, and total count
            if negative_count > positive_count:
                purity = negative_count / count
            else:
                purity = positive_count / count

            purities = np.append(purities, purity)

        updatePlot(X, reference_vecs, cluster_associations, iteration, purities)

    return 0

if __name__ == '__main__':

    args = sys.argv
    raw_data = []
    path_to_file = ""

    # Check args
    if len(args) == 2:
        path_to_file = args[1]
        print("Using path " + path_to_file)
    else:
        print("Please run this script as cluser <path_to_file>")
        exit(1)

    # Read Data Matx from File
    if ".csv" in path_to_file:
        read = genfromtxt(path_to_file,
                                         dtype=None, delimiter =",")
        raw_data = [list(item) for item in read]
        raw_data = np.asarray(raw_data)

    # Separate Class Labels
    Y = raw_data.T[0].T
    X = np.delete(raw_data.T, 0,0).T



    #Standardize Features of X
    X = X - X.mean(axis=0)
    X = X / X.std(axis=0, ddof=1)

    #print(X[0])
    # last two features of X
    kmeansdata = X.T[6:8].T

    result = myKMeans(kmeansdata, 3, Y)

    test = np.vstack((Y.T, kmeansdata.T)).T

    # Plot
