import os;
import sys
from PIL import Image;
import numpy as np;
import math
from numpy import linalg as LA
import matplotlib.pyplot as plt

numSamplesToTest = 154;
subsampleSize = 40;

def imgfrom1600arr(x):
    normalized = (x - min(x)) / (max(x) - min(x))
    normalized = normalized * 255
    resized = np.resize(normalized, (40, 40))

    # Visualization of Primary Principle component
    im = Image.fromarray(np.uint8(resized))
    return im

def standardize(A): #untested

    sample = A[0];
    for i in range(0, len(A[0])):
        data = []
        for samples in A:
            data.append(samples[i])
        # Now we have data for each feature stored in data
        mean = np.mean(data)
        std = np.std(data);
        for j in range(0, len(A)):
            if std != 0:
                A[j][i] = (A[j][i] - mean) / std;

    return A

def maxes(arr, n):
    arrCP = arr.copy()
    maxes = np.zeros(n)
    for num in range (0, n):
        for i in range(0, len(arr)):
            if arrCP[i] > maxes[num]:
                maxes[num] = i
        arrCP[maxes[num].astype(int)] = -999999

    return maxes


def projectPoints(d, v1, v2):

    eigenData = [];
    for observation in d:
        projectedData = [ np.dot(observation, v1), np.dot(observation, v2) ]
        eigenData.append(projectedData)

    return eigenData

def projectPoints1D(d, primaryComponent):
    eigenData = []
    for observation in d:
        projectedData = [np.dot(observation, primaryComponent)]
        eigenData.append(projectedData)

    return eigenData

def readYaleFaces(facesDir):
    data = np.ones((154, 1600))
    count = 0;
    for root, dirs, files in os.walk(facesDir):
        for file in files:
            if file.startswith("subject"):
                im  = Image.open(os.path.join(facesDir, file), 'r');
                arr = np.array(im)

                m = len(arr)
                n = len(arr[0])

                # Subsample the image using a mean
                subsampledImage = np.ones((subsampleSize, subsampleSize))

                iincr = int(math.ceil(m/subsampleSize))
                jincr = int(math.ceil(n/subsampleSize))
                ioffset = 0;
                joffset = 0;

                for x in range(0, subsampleSize):
                    for y in range(0, subsampleSize):

                        # Read One Group of Pixels
                        summation = 0;
                        avg = 0
                        for i in range (0,iincr):
                            for j in range(0, jincr):
                                if(ioffset+i < m and joffset+j < n):
                                    summation += arr[ioffset+i][joffset+j]
                        avg = summation / (iincr*jincr);
                        subsampledImage[x][y] = avg
                        joffset += jincr
                    ioffset += iincr
                    joffset =0;
                im = Image.fromarray(subsampledImage)

                # np.append(data[], subsampledImage.flatten())
                data[count] = subsampledImage.flatten()
                if count > numSamplesToTest:
                    break
                else:
                    count += 1
    return data

class readData:

    args = sys.argv
    facesDir = "."
    if len(args) == 2:
        facesDir = args[1]
        print("Using directory " + facesDir)
    else:
        print("Please run this script as facespca <path_to_yalfaces_dir>")

    # Read Files into data
    data = readYaleFaces(facesDir)
    # Now we have the subsampled data

    # Standardize Data
    data2 = standardize(data) # My standardized data does not match what I expected it to

    # Compute covariance matrix (sigma)
    transposedData = np.array(data2).transpose()
    # Transpose data so that the rows are now our features
    sigma = np.cov(transposedData)

    # Find Eigenvalues of covariance matrix
    w,v = LA.eig(sigma);

    #Find indices of max two eigenvalues
    indix = maxes(w, 2)
    v0 = v[indix[0].astype(int)]
    v1 = v[indix[1].astype(int)]

    # Project Onto first two eigenvalues
    eigenSpaceData = projectPoints(data2, v0, v1)
    # Should now be a matrix with rows as projected features
    # Let's transform it back so that our rows are observations
    eigenSpaceData = np.array(eigenSpaceData).transpose()

    #plot data
    plt.plot(eigenSpaceData[0], eigenSpaceData[1], 'ro') # 'ro' means plot red points
    plt.axis([-10, 10, -10, 10])
    plt.show();
    # print(eigenSpaceData) # Getting imaginary values for thiss

    # Calculate alpha

    np.flipud(w)

    k = 0
    alpha = 0
    while(alpha < .95):
        k += 1
        num = sum(abs(w[:k]))
        print(num)
        den = sum(abs(w))
        alpha = num/den
        print("Alpha= " + str(alpha))

    print("k value = " + str(k))

    # pcProjection = projectPoints1D(data2, v0)

    #Let's copy the primary PC and standardize it for output
    im = imgfrom1600arr(v0)
    im.show()

    # Reconstruct the first person using the first k most significant eigenvectors
    # firstPerson = data2[0]
    # firstPersonFirstPCA = projectPoints1D(firstPerson, v0)
    # im = imgfrom1600arr(firstPersonFirstPCA)
    # im.show
    exit(0)

